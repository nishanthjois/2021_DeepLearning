{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8-GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPDoC2W2OzMd5iGMibjJF8u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishanthjois/2021_DeepLearning/blob/main/8_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9ptOTom3CmR",
        "outputId": "64ca52de-82dc-4e68-97b2-14866c9bc632"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.8 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.0.3.tar.gz (370 kB)\n",
            "\u001b[K     |████████████████████████████████| 370 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Collecting rdflib\n",
            "  Downloading rdflib-6.1.1-py3-none-any.whl (482 kB)\n",
            "\u001b[K     |████████████████████████████████| 482 kB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 581 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (4.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib->torch-geometric) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.0.3-py3-none-any.whl size=581968 sha256=47244049d64f655ebfb66e4b3f3d0f1314ab833618091aa7059498fc73781af4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/2a/58/87ce0508964d4def1aafb92750c4f3ac77038efd1b9a89dcf5\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, yacs, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.1 rdflib-6.1.1 torch-geometric-2.0.3 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gQsKXE7-1Wq9"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download data\n",
        "!apt-get install p7zip\n",
        "!curl -Lo yoochoose-data.7z https://s3-eu-west-1.amazonaws.com/yc-rdata/yoochoose-data.7z\n",
        "!7z x yoochoose-data.7z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVTeRL0c1q2g",
        "outputId": "318d3cee-ae17-4ba0-ee1a-b98bf153304f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip is already the newest version (16.02+dfsg-6).\n",
            "p7zip set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  273M  100  273M    0     0  24.5M      0  0:00:11  0:00:11 --:--:-- 28.3M\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 287211932 bytes (274 MiB)\n",
            "\n",
            "Extracting archive: yoochoose-data.7z\n",
            "--\n",
            "Path = yoochoose-data.7z\n",
            "Type = 7z\n",
            "Physical Size = 287211932\n",
            "Headers Size = 255\n",
            "Method = LZMA:24\n",
            "Solid = +\n",
            "Blocks = 2\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 3\b\b\b\b\b\b      \b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 4\n",
            "Size:       1914111754\n",
            "Compressed: 287211932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wf2AY_xL4IRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv yoo* data/"
      ],
      "metadata": {
        "id": "hi5d1XiC1x9m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataloader.py\n",
        "import torch\n",
        "from torch_geometric.data import Dataset\n",
        "\n",
        "\n",
        "# The class inherits the base class Dataset from pytorch\n",
        "class LoadData(Dataset):  # for training/testing\n",
        "    def __init__(self, data_path):\n",
        "        super(LoadData, self).__init__()\n",
        "        self.data = torch.load(data_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fu31yJ3R4RM0",
        "outputId": "c245d87e-4933-4281-9125-e3769e808c7c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataloader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gnn.py\n",
        "# # cimport matplotlib.pyplot as plt\n",
        "#import osmnx as ox\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.nn import TopKPooling\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "#from data_loader import YooChooseDataset\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv, SAGEConv, SGConv, SplineConv\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "import torch.nn.functional as F\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "datatset_size = 10000\n",
        "\n",
        "clicks_df = pd.read_csv('./data/yoochoose-clicks.dat', header=None)\n",
        "clicks_df.columns = ['session_id', 'timestamp', 'item_id', 'category']\n",
        "print(clicks_df.head(5))\n",
        "\n",
        "buy_df = pd.read_csv('./data/yoochoose-buys.dat', header=None)\n",
        "buy_df.columns = ['session_id', 'timestamp', 'item_id', 'price', 'quantity']\n",
        "print(buy_df.head(5))\n",
        "\n",
        "item_encoder = LabelEncoder()\n",
        "clicks_df['item_id'] = item_encoder.fit_transform(clicks_df.item_id)\n",
        "print(clicks_df.head())\n",
        "\n",
        "#randomly sample a couple of them\n",
        "sampled_session_id = np.random.choice(clicks_df.session_id.unique(), datatset_size, replace=False)\n",
        "clicks_df = clicks_df.loc[clicks_df.session_id.isin(sampled_session_id)]\n",
        "print(clicks_df.nunique())\n",
        "\n",
        "clicks_df['label'] = clicks_df.session_id.isin(buy_df.session_id)\n",
        "print(clicks_df.head())\n",
        "\n",
        "print(clicks_df.item_id.max() + 1)\n",
        "\n",
        "\n",
        "class YooChooseBinaryDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(YooChooseBinaryDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load('./data/processed.dataset')\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['../input/yoochoose_click_binary_1M_sess.dataset']\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "\n",
        "        data_list = []\n",
        "\n",
        "        # process by session_id\n",
        "        grouped = clicks_df.groupby('session_id')\n",
        "        for session_id, group in tqdm(grouped):\n",
        "            sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
        "            group = group.reset_index(drop=True)\n",
        "            group['sess_item_id'] = sess_item_id\n",
        "            node_features = group.loc[group.session_id == session_id, ['sess_item_id', 'item_id']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
        "\n",
        "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
        "            target_nodes = group.sess_item_id.values[1:]\n",
        "            source_nodes = group.sess_item_id.values[:-1]\n",
        "\n",
        "            edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
        "            x = node_features\n",
        "\n",
        "            y = torch.FloatTensor([group.label.values[0]])\n",
        "\n",
        "            data = Data(x=x, edge_index=edge_index, y=y)\n",
        "            data_list.append(data)\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), './data/processed.dataset')\n",
        "\n",
        "\n",
        "\n",
        "dataset = YooChooseBinaryDataset('./')\n",
        "one_tenth_length = int(len(dataset) * 0.1)\n",
        "dataset = dataset.shuffle()\n",
        "train_dataset = dataset[:one_tenth_length * 8]\n",
        "val_dataset = dataset[one_tenth_length * 8:one_tenth_length * 9]\n",
        "test_dataset = dataset[one_tenth_length * 9:]\n",
        "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "\n",
        "embed_dim = 128\n",
        "different_ids = 52707\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(embed_dim, 128)\n",
        "        self.pool1 = TopKPooling(128, ratio=0.8)\n",
        "        self.conv2 = SAGEConv(128, 128)\n",
        "        self.pool2 = TopKPooling(128, ratio=0.8)\n",
        "        self.conv3 = SAGEConv(128, 128)\n",
        "        self.pool3 = TopKPooling(128, ratio=0.8)\n",
        "        self.item_embedding = torch.nn.Embedding(num_embeddings=different_ids, embedding_dim=embed_dim)\n",
        "        #self.item_embedding = torch.nn.Embedding(num_embeddings=clicks_df.item_id.max() + 1, embedding_dim=embed_dim)\n",
        "        self.lin1 = torch.nn.Linear(256, 128)\n",
        "        self.lin2 = torch.nn.Linear(128, 64)\n",
        "        self.lin3 = torch.nn.Linear(64, 1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.item_embedding(x)\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
        "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
        "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = x1 + x2 + x3\n",
        "\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act2(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def train(loader):\n",
        "    model.train()\n",
        "\n",
        "    loss_all = 0\n",
        "    num_epochs = 30\n",
        "    for epoch in range(num_epochs):\n",
        "        print(epoch)\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            label = data.y.to(device)\n",
        "            loss = crit(output, label)\n",
        "            loss.backward()\n",
        "            loss_all += data.num_graphs * loss.item()\n",
        "            optimizer.step()\n",
        "            #print(loss)\n",
        "    return loss_all / len(train_dataset)\n",
        "\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "crit = torch.nn.BCELoss()\n",
        "train_loader = DataLoader(train_dataset, batch_size=512)\n",
        "test_loader = DataLoader(test_dataset, batch_size=512)\n",
        "val_loader = DataLoader(val_dataset, batch_size=512)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train(train_loader)\n",
        "\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    print(len(loader))\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            pred = model(data).detach().cpu().numpy()\n",
        "\n",
        "            label = data.y.detach().cpu().numpy()\n",
        "            predictions.append(pred)\n",
        "            labels.append(label)\n",
        "\n",
        "    #if len(loader) == 0:\n",
        "    #     return\n",
        "    predictions = np.hstack(predictions)\n",
        "    labels = np.hstack(labels)\n",
        "\n",
        "    return roc_auc_score(labels, predictions)\n",
        "\n",
        "\n",
        "for epoch in range(1):\n",
        "    train_acc = evaluate(train_loader)\n",
        "    val_acc = evaluate(val_loader)\n",
        "    test_acc = evaluate(test_loader)\n",
        "    print(epoch, train_acc, val_acc, test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzzw9f5T4JA8",
        "outputId": "732a781d-ca98-40fd-d121-aa13899431f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gnn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "from torch_geometric.nn import TopKPooling, SAGEConv, GraphConv\n",
        "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, different_ids=52737, embed_dim=128):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(embed_dim, 128)\n",
        "        self.pool1 = TopKPooling(128, ratio=0.5)\n",
        "        self.conv2 = SAGEConv(128, 128)\n",
        "        self.pool2 = TopKPooling(128, ratio=0.5)\n",
        "        self.conv3 = SAGEConv(128, 128)\n",
        "        self.pool3 = TopKPooling(128, ratio=0.5)\n",
        "        self.item_embedding = torch.nn.Embedding(num_embeddings=different_ids, embedding_dim=embed_dim)\n",
        "        self.lin1 = torch.nn.Linear(256, 128)\n",
        "        self.lin2 = torch.nn.Linear(128, 64)\n",
        "        self.lin3 = torch.nn.Linear(64, 1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(128)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
        "        self.act1 = torch.nn.ReLU()\n",
        "        self.act2 = torch.nn.ReLU()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.item_embedding(x)\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
        "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
        "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = x1 + x2 + x3\n",
        "\n",
        "        x = self.lin1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act2(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = torch.sigmoid(self.lin3(x)).squeeze(1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net2(torch.nn.Module):\n",
        "    def __init__(self, different_ids=52737, embed_dim=512):\n",
        "        super(Net2, self).__init__()\n",
        "\n",
        "        self.item_embedding = torch.nn.Embedding(num_embeddings=different_ids, embedding_dim=embed_dim)\n",
        "\n",
        "        self.conv1 = SAGEConv(embed_dim, 512)\n",
        "        self.pool1 = TopKPooling(512, ratio=0.8)\n",
        "        self.conv2 = SAGEConv(512, 512)\n",
        "        self.pool2 = TopKPooling(512, ratio=0.8)\n",
        "        self.conv3 = SAGEConv(512, 512)\n",
        "        self.pool3 = TopKPooling(512, ratio=0.8)\n",
        "        self.lin1 = torch.nn.Linear(1024, 512)\n",
        "        self.lin2 = torch.nn.Linear(512, 256)\n",
        "        self.lin3 = torch.nn.Linear(256, 128)\n",
        "        self.lin4 = torch.nn.Linear(128, 64)\n",
        "        self.lin5 = torch.nn.Linear(64, 1)\n",
        "        self.bn1 = torch.nn.BatchNorm1d(256)\n",
        "        self.bn2 = torch.nn.BatchNorm1d(128)\n",
        "        self.bn3 = torch.nn.BatchNorm1d(64)\n",
        "        self.act = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.item_embedding(x)\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
        "\n",
        "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
        "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
        "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
        "\n",
        "        x = x1 + x2 + x3\n",
        "\n",
        "        x = self.lin1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.act(x)\n",
        "        x = self.lin3(x)\n",
        "        x = self.act(x)\n",
        "        x = self.lin4(x)\n",
        "        x = self.act(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = torch.sigmoid(self.lin5(x)).squeeze(1)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtBFlKYK4Bbf",
        "outputId": "34864d10-aaf8-4216-b2b4-cc219acd2e60"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile preprocessing.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "\n",
        "datatset_size = 10000\n",
        "\n",
        "# yoochoose-clicks.dat - Click events. Each record/line in the file has the following fields:\n",
        "#     Session ID – the id of the session. In one session there are one or many clicks.\n",
        "#     Timestamp – the time when the click occurred.\n",
        "#     Item ID – the unique identifier of the item.\n",
        "#     Category – the category of the item.\n",
        "clicks_df = pd.read_csv('./data/yoochoose-clicks.dat', header=None)\n",
        "clicks_df.columns = ['session_id', 'timestamp', 'item_id', 'category']\n",
        "\n",
        "# filter out item session with length < 2\n",
        "clicks_df['valid_session'] = clicks_df.session_id.map(clicks_df.groupby('session_id')['item_id'].size() > 2)\n",
        "clicks_df = clicks_df.loc[clicks_df.valid_session].drop('valid_session',axis=1)\n",
        "print(clicks_df.nunique())\n",
        "print(clicks_df.head(5))\n",
        "\n",
        "# yoochoose-buys.dat - Buy events. Each record/line in the file has the following fields:\n",
        "#     Session ID - the id of the session. In one session there are one or many buying events.\n",
        "#     Timestamp - the time when the buy occurred.\n",
        "#     Item ID – the unique identifier of item.\n",
        "#     Price – the price of the item.\n",
        "#     Quantity – how many of this item were bought.\n",
        "buy_df = pd.read_csv('./data/yoochoose-buys.dat', header=None)\n",
        "buy_df.columns = ['session_id', 'timestamp', 'item_id', 'price', 'quantity']\n",
        "print(buy_df.head())\n",
        "\n",
        "# Encode item_id with values between 0 and n_classes - 1 (for embedding)\n",
        "item_encoder = LabelEncoder()\n",
        "clicks_df['item_id'] = item_encoder.fit_transform(clicks_df.item_id)\n",
        "print(min(clicks_df['item_id']))\n",
        "print(max(clicks_df['item_id']))\n",
        "print(clicks_df.head())\n",
        "\n",
        "# randomly sample a couple of them\n",
        "sampled_session_id = np.random.choice(clicks_df.session_id.unique(), datatset_size, replace=False)\n",
        "clicks_df = clicks_df.loc[clicks_df.session_id.isin(sampled_session_id)]\n",
        "print(clicks_df.nunique())\n",
        "\n",
        "# average length of session \n",
        "print(clicks_df.groupby('session_id')['item_id'].size().mean())\n",
        "\n",
        "# add a boolean column named label to the clicks_df representing wether the click in the session is\n",
        "# buy or not\n",
        "clicks_df['label'] = clicks_df.session_id.isin(buy_df.session_id)\n",
        "\n",
        "print(clicks_df.label.value_counts())\n",
        "print(clicks_df.label.unique())\n",
        "print(clicks_df.item_id.max() + 1)\n",
        "\n",
        "data_list = []\n",
        "\n",
        "# process by session_id\n",
        "grouped = clicks_df.groupby('session_id')\n",
        "for session_id, group in tqdm(grouped):\n",
        "    sess_item_id = LabelEncoder().fit_transform(group.item_id)\n",
        "    group = group.reset_index(drop=True)\n",
        "    group['sess_item_id'] = sess_item_id\n",
        "    node_features = group.loc[group.session_id == session_id, ['sess_item_id', 'item_id', 'timestamp']].sort_values('sess_item_id').item_id.drop_duplicates().values\n",
        "\n",
        "    node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
        "    target_nodes = group.sess_item_id.values[1:]\n",
        "    source_nodes = group.sess_item_id.values[:-1]\n",
        "\n",
        "    edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
        "    x = node_features\n",
        "\n",
        "    y = torch.FloatTensor([group.label.values[0]])\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, y=y)\n",
        "    data_list.append(data)\n",
        "\n",
        "torch.save(data_list, './data/processed.dataset')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow434gh535pY",
        "outputId": "c1254601-1e21-45a0-e2a0-deb28bd82989"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing preprocessing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.py\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def test(test_loader, model, device):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    labels = []\n",
        "    print(len(test_loader))\n",
        "    nb = len(test_loader)\n",
        "\n",
        "    # Disable gradients\n",
        "    pbar = tqdm(enumerate(test_loader), total=nb)\n",
        "    for batch_idx, data in pbar:\n",
        "        with torch.no_grad():\n",
        "            data = data.to(device)\n",
        "            pred = model(data).detach().cpu().numpy()\n",
        "\n",
        "            label = data.y.detach().cpu().numpy()\n",
        "\n",
        "            predictions.append(pred)\n",
        "            labels.append(label)\n",
        "\n",
        "    predictions = np.hstack(predictions)\n",
        "    labels = np.hstack(labels)\n",
        "\n",
        "    #predictions = binarize(predictions, threshold=0.5, copy=True)\n",
        "    #labels = binarize(labels, threshold=0.5, copy=True)\n",
        "\n",
        "\n",
        "\n",
        "    return roc_auc_score(labels, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNzcyX_T30Hi",
        "outputId": "266fa9f3-bf08-4771-d5bc-9b59fe43e80b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import os\n",
        "import torch\n",
        "from dataloader import LoadData\n",
        "from torch_geometric.data import DataLoader\n",
        "import argparse\n",
        "from model import Net, Net2\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from test import test\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "wdir = 'weights' + os.sep  # weights dir\n",
        "last = wdir + 'last.pt'\n",
        "best = wdir + 'best.pt'\n",
        "results_file = 'results.txt'\n",
        "\n",
        "\n",
        "def train(args, model, device, train_loader, test_loader, val_loader, optimizer, save=True):\n",
        "\n",
        "    # writer will output to ./runs/ directory by default\n",
        "    tb_writer = SummaryWriter()\n",
        "\n",
        "    # because this is a binary classification problem\n",
        "    crit = torch.nn.BCELoss()\n",
        "\n",
        "    # the number of batches\n",
        "    nb = train_loader.__len__()\n",
        "\n",
        "    # initialize the roc auc score\n",
        "    best_roc_auc_score = 0\n",
        "    start_epoch = 0\n",
        "\n",
        "    if args.weights.endswith('.pt'):  # pytorch format\n",
        "\n",
        "        chkpt = torch.load(args.weights, map_location=device)\n",
        "\n",
        "        # load model\n",
        "        try:\n",
        "            model.load_state_dict(chkpt['model'], strict=False)\n",
        "        except KeyError as e:\n",
        "            print(e)\n",
        "            exit()\n",
        "\n",
        "        # load optimizer\n",
        "        if chkpt['optimizer'] is not None:\n",
        "            optimizer.load_state_dict(chkpt['optimizer'])\n",
        "            best_roc_auc_score = chkpt['best_fitness']\n",
        "\n",
        "        # load results\n",
        "        if chkpt.get('training_results') is not None:\n",
        "            with open(results_file, 'w') as file:\n",
        "                file.write(chkpt['training_results'])  # write results.txt\n",
        "\n",
        "        start_epoch = chkpt['epoch'] + 1\n",
        "        del chkpt\n",
        "\n",
        "    for epoch in range(start_epoch, args.epochs + 1):\n",
        "\n",
        "        # ----------------------------------------------------------------\n",
        "        # start epoch ----------------------------------------------------\n",
        "        # ----------------------------------------------------------------\n",
        "\n",
        "        print('\\tEPOCH', epoch, '/', args.epochs)\n",
        "\n",
        "        model.train()\n",
        "        pbar = tqdm(enumerate(train_loader), total=nb)\n",
        "\n",
        "        for batch_idx, data in pbar:\n",
        "\n",
        "            # ----------------------------------------------------------------\n",
        "            # start batch ----------------------------------------------------\n",
        "            # ----------------------------------------------------------------\n",
        "\n",
        "            data = data.to(device)\n",
        "            # zero the gradient buffers\n",
        "            optimizer.zero_grad()\n",
        "            # classify batch\n",
        "            output = model(data)\n",
        "            label = data.y.to(device)\n",
        "            loss = crit(output, label)\n",
        "            print(loss)\n",
        "            # loss = F.nll_loss(output, label)\n",
        "            loss.backward()\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % args.log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "            # ----------------------------------------------------------------\n",
        "            # end batch ------------------------------------------------------\n",
        "            # ----------------------------------------------------------------\n",
        "\n",
        "        # Update scheduler\n",
        "        # scheduler.step()\n",
        "\n",
        "        final_epoch = epoch + 1 == args.epochs\n",
        "\n",
        "        # Update best roc_auc_score\n",
        "        roc_auc_score = test(test_loader, model, device)\n",
        "        roc_auc_score2 = test(val_loader, model, device)\n",
        "        print('test roc auc score:', roc_auc_score, \"val\", roc_auc_score2)\n",
        "\n",
        "        # Write Tensorboard results\n",
        "        if tb_writer:\n",
        "            x = [roc_auc_score, roc_auc_score2]\n",
        "            titles = ['ROC AUC TEST', 'ROC AUC VAL']\n",
        "            for xi, title in zip(x, titles):\n",
        "                tb_writer.add_scalar(title, xi, epoch)\n",
        "\n",
        "        # Write epoch results\n",
        "        with open(results_file, 'a') as f:\n",
        "            f.write('%f' % roc_auc_score + '\\n')\n",
        "\n",
        "        if roc_auc_score > best_roc_auc_score:\n",
        "            best_roc_auc_score = roc_auc_score\n",
        "\n",
        "        # Save training results\n",
        "        if save:\n",
        "            with open(results_file, 'r') as f:\n",
        "                # Create checkpoint\n",
        "                chkpt = {'epoch': epoch,\n",
        "                         'best_fitness': best_roc_auc_score,\n",
        "                         'training_results': f.read(),\n",
        "                         'model': model.state_dict(),\n",
        "                         'optimizer': None if final_epoch else optimizer.state_dict()}\n",
        "\n",
        "            # Save last checkpoint\n",
        "            torch.save(chkpt, last)\n",
        "\n",
        "            # Save best checkpoint\n",
        "            if round(best_roc_auc_score, 2) == round(roc_auc_score, 2):\n",
        "                torch.save(chkpt, best)\n",
        "\n",
        "            # Delete checkpoint\n",
        "            del chkpt\n",
        "\n",
        "    # ----------------------------------------------------------------\n",
        "    # end epoch ------------------------------------------------------\n",
        "    # ----------------------------------------------------------------\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='PyTorch Battery')\n",
        "\n",
        "    parser.add_argument('--resume', action='store_true',\n",
        "                        help='resume training from last.pt')\n",
        "    parser.add_argument('--batch-size', type=int, default=512, metavar='N',\n",
        "                        help='input batch size for training (default: 64)')\n",
        "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                        help='disables CUDA training')\n",
        "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
        "                        help='learning rate (default: 1.0)')\n",
        "    parser.add_argument('--epochs', type=int, default=400, metavar='N',\n",
        "                        help='number of epochs to train (default: 14)')\n",
        "    parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
        "                        help='how many batches to wait before logging training status')\n",
        "    parser.add_argument('--weights', type=str, default='',\n",
        "                        help='initial weights path')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    args.weights = last if args.resume else args.weights\n",
        "\n",
        "    print('\\n\\n\\tTrain...\\n')\n",
        "\n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "    dataset = LoadData('./data/processed.dataset')\n",
        "\n",
        "    one_tenth_length = int(len(dataset) * 0.001)\n",
        "    train_dataset = dataset[:one_tenth_length * 8]\n",
        "    val_dataset = dataset[one_tenth_length * 8:one_tenth_length * 9]\n",
        "    test_dataset = dataset[one_tenth_length * 9:]\n",
        "\n",
        "    print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=args.batch_size,\n",
        "                              num_workers=1,\n",
        "                              shuffle=True,\n",
        "                              pin_memory=True)\n",
        "\n",
        "    val_loader = DataLoader(val_dataset,\n",
        "                            batch_size=args.batch_size,\n",
        "                            num_workers=1,\n",
        "                            shuffle=True,\n",
        "                            pin_memory=True)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset,\n",
        "                             batch_size=args.batch_size,\n",
        "                             num_workers=1,\n",
        "                             shuffle=True,\n",
        "                             pin_memory=True)\n",
        "\n",
        "    train(args, model, device, train_loader, test_loader, val_loader, optimizer)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RS-0osO3Gfm",
        "outputId": "9907253e-00b4-4464-8627-39ab435f4f0a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 preprocessing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoenq6Qs42-s",
        "outputId": "b1657d8d-1d0f-4f6d-fcab-fbe66d123996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys:1: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjIZ_dXL1-c0",
        "outputId": "25ffee56-0f8c-418a-fb8b-b79238df025f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tTrain...\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 209, in <module>\n",
            "    main()\n",
            "  File \"train.py\", line 178, in main\n",
            "    dataset = LoadData('./data/processed.dataset')\n",
            "  File \"/content/dataloader.py\", line 9, in __init__\n",
            "    self.data = torch.load(data_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './data/processed.dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mhTmsq6S3BRp"
      }
    }
  ]
}