{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishanthjois/2021_DeepLearning/blob/main/2_models_vsknn_recohut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nnaEliACb_a"
      },
      "outputs": [],
      "source": [
        "# default_exp models.vsknn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfmY6V0FCb_e"
      },
      "source": [
        "# VSKNN\n",
        "> Vector Multiplication Session-Based kNN\n",
        "\n",
        "The idea of this variant is to put more emphasis on the more recent events of a session when computing the similarities. Instead of encoding a session as a binary vector, we use real-valued vectors to encode the current session. Only the very last element of the session obtains a value of “1”; the weights of the other elements are determined using a linear decay function that depends on the position of the element within the session, where elements appearing earlier in the session obtain a lower weight. As a result, when using the dot product as a similarity function between the current weight-encoded session and a binary-encoded past session, more emphasis is given to elements that appear later in the sessions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztEMph00Cmsf",
        "outputId": "2cff4435-4aee-4602-f1f1-7921ca8a2365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nbdev\n",
            "  Downloading nbdev-1.1.23-py3-none-any.whl (46 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████                         | 10 kB 37.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 30 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 40 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 46 kB 3.0 MB/s \n",
            "\u001b[?25hCollecting fastcore\n",
            "  Downloading fastcore-1.3.27-py3-none-any.whl (56 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▊                          | 10 kB 47.5 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20 kB 54.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30 kB 63.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40 kB 51.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 51 kB 56.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 56 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from nbdev) (21.1.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from nbdev) (3.13)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from nbdev) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client<7.0 in /usr/local/lib/python3.7/dist-packages (from nbdev) (5.3.5)\n",
            "Collecting ghapi\n",
            "  Downloading ghapi-0.1.19-py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 464 kB/s \n",
            "\u001b[?25hRequirement already satisfied: nbconvert<6 in /usr/local/lib/python3.7/dist-packages (from nbdev) (5.6.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from nbdev) (1.0.0)\n",
            "Collecting fastrelease\n",
            "  Downloading fastrelease-0.1.12-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: nbformat>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from nbdev) (5.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nbdev) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev) (5.1.1)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev) (5.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev) (22.3.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<7.0->nbdev) (4.9.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (2.6.1)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (2.11.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (0.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (4.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert<6->nbdev) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.4->nbconvert<6->nbdev) (2.0.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev) (4.3.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.4.0->nbdev) (0.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (5.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (4.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (3.10.0.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (0.18.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4.0->nbdev) (3.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->jupyter-client<7.0->nbdev) (1.15.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert<6->nbdev) (0.5.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->nbdev) (5.5.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->nbdev) (0.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->nbdev) (0.2.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (7.6.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (5.2.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->nbdev) (5.3.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nbdev) (3.5.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->nbdev) (1.0.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->nbdev) (0.13.1)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->nbdev) (0.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->nbdev) (3.0.7)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->nbdev) (2.0.0)\n",
            "Installing collected packages: fastcore, ghapi, fastrelease, nbdev\n",
            "Successfully installed fastcore-1.3.27 fastrelease-0.1.12 ghapi-0.1.19 nbdev-1.1.23\n"
          ]
        }
      ],
      "source": [
        "!pip install nbdev fastcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdc6Pl1RC7Ov",
        "outputId": "6ae75421-fd98-4d53-d260-537fadefe6d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "p7zip is already the newest version (16.02+dfsg-6).\n",
            "p7zip set to manually installed.\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  273M  100  273M    0     0  19.5M      0  0:00:14  0:00:14 --:--:-- 22.1M\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 287211932 bytes (274 MiB)\n",
            "\n",
            "Extracting archive: yoochoose-data.7z\n",
            "--\n",
            "Path = yoochoose-data.7z\n",
            "Type = 7z\n",
            "Physical Size = 287211932\n",
            "Headers Size = 255\n",
            "Method = LZMA:24\n",
            "Solid = +\n",
            "Blocks = 2\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  0% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  1% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  2% - yoochoose-buys.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                         \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  3% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  4% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  5% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  6% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  7% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  9% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 10% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 12% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 13% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 15% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 16% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 17% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 18% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 20% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 21% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 22% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 23% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 25% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 26% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 28% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 29% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 31% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 33% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 35% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 36% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 37% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 38% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 39% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 40% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 41% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 42% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 43% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 45% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 46% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 48% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 51% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 52% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 53% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 56% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 57% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 60% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 65% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 69% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 70% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 71% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 72% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 74% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 77% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 78% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 79% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 1 - yoochoose-clicks.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 81% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 84% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 94% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 96% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 97% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 2 - yoochoose-test.dat\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                           \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Files: 4\n",
            "Size:       1914111754\n",
            "Compressed: 287211932\n"
          ]
        }
      ],
      "source": [
        "#download data\n",
        "!apt-get install p7zip\n",
        "!curl -Lo yoochoose-data.7z https://s3-eu-west-1.amazonaws.com/yc-rdata/yoochoose-data.7z\n",
        "!7z x yoochoose-data.7z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-7tSzSN-Cb_g"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yR5-SZtMCb_h"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "from operator import itemgetter\n",
        "from math import sqrt\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import log10\n",
        "import gc\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#export\n",
        "import math\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#hide\n",
        "from nbdev.showdoc import *\n",
        "from fastcore.nb_imports import *\n",
        "from fastcore.test import *\n",
        "\n",
        "#export\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import log10\n",
        "import collections as col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgVcmY5xCb_i"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class VMContextKNN:\n",
        "    '''\n",
        "    VMContextKNN( k, sample_size=1000, similarity='cosine', weighting='div', weighting_score='div_score', session_key = 'SessionId', item_key= 'ItemId')\n",
        "    Parameters\n",
        "    -----------\n",
        "    k : int\n",
        "        Number of neighboring session to calculate the item scores from. (Default value: 200)\n",
        "    sample_size : int\n",
        "        Defines the length of a subset of all training sessions to calculate the nearest neighbors from. (Default value: 2000)\n",
        "    similarity : string\n",
        "        String to define the method for the similarity calculation (jaccard, cosine, binary, tanimoto). (default: cosine)\n",
        "    weighting : string\n",
        "        Decay function to determine the importance/weight of individual actions in the current session (linear, same, div, log, quadratic). (default: div)\n",
        "    weighting_score : string\n",
        "        Decay function to lower the score of candidate items from a neighboring sessions that were selected by less recently clicked items in the current session. (linear, same, div, log, quadratic). (default: div_score)\n",
        "    session_key : string\n",
        "        Header of the session ID column in the input file. (default: 'SessionId')\n",
        "    item_key : string\n",
        "        Header of the item ID column in the input file. (default: 'ItemId')\n",
        "    '''\n",
        "    def __init__( self, k=200, sample_size=0, similarity='cosine', weighting='div', weighting_score='div_score', session_key = 'SessionId', item_key= 'ItemId'):\n",
        "       \n",
        "        self.k = k\n",
        "        self.sample_size = sample_size\n",
        "        self.weighting = weighting\n",
        "        self.weighting_score = weighting_score\n",
        "        self.similarity = similarity\n",
        "        self.session_key = session_key\n",
        "        self.item_key = item_key\n",
        "        \n",
        "        #updated while recommending\n",
        "        self.session = -1\n",
        "        self.session_items = []\n",
        "        self.relevant_sessions = set()\n",
        "\n",
        "        # cache relations once at startup\n",
        "        self.session_item_map = dict() \n",
        "        self.item_session_map = dict()\n",
        "        self.session_time = dict()\n",
        "        self.min_time = -1\n",
        "        \n",
        "        self.sim_time = 0\n",
        "        \n",
        "    def fit(self, train, items=None):\n",
        "        '''\n",
        "        Trains the predictor.\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        data: pandas.DataFrame\n",
        "            Training data. It contains the transactions of the sessions. It has one column for session IDs, one for item IDs and one for the timestamp of the events (unix timestamps).\n",
        "            It must have a header. Column names are arbitrary, but must correspond to the ones you set during the initialization of the network (session_key, item_key, time_key properties).\n",
        "        '''\n",
        "        self.items_ids = list(train[self.item_key].unique())\n",
        "        train[self.item_key] = train[self.item_key].astype('category')\n",
        "        self.new_old = dict(enumerate(train[self.item_key].cat.categories))\n",
        "        self.old_new = {y:x for x,y in self.new_old.items()}\n",
        "        train[[self.item_key]] = train[[self.item_key]].apply(lambda x: x.cat.codes)\n",
        "        \n",
        "        self.freqs = dict(train[self.item_key].value_counts())\n",
        "        \n",
        "        self.num_items = train[self.item_key].max()\n",
        "        index_session = train.columns.get_loc( self.session_key )\n",
        "        index_item = train.columns.get_loc( self.item_key )\n",
        "        \n",
        "        session = -1\n",
        "        session_items = set()\n",
        "        for row in train.itertuples(index=False):\n",
        "            # cache items of sessions\n",
        "            if row[index_session] != session:\n",
        "                if len(session_items) > 0:\n",
        "                    self.session_item_map.update({session : session_items})\n",
        "                session = row[index_session]\n",
        "                session_items = set()\n",
        "            session_items.add(row[index_item])\n",
        "            \n",
        "            # cache sessions involving an item\n",
        "            map_is = self.item_session_map.get( row[index_item] )\n",
        "            if map_is is None:\n",
        "                map_is = set()\n",
        "                self.item_session_map.update({row[index_item] : map_is})\n",
        "            map_is.add(row[index_session])\n",
        "            \n",
        "        # Add the last tuple    \n",
        "        self.session_item_map.update({session : session_items})\n",
        "        self.predict_for_item_ids = list(range(1, self.num_items+1))\n",
        "        \n",
        "        \n",
        "    def predict_next(self, session_items, k):\n",
        "        '''\n",
        "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
        "                \n",
        "        Parameters\n",
        "        --------\n",
        "        session_items : List\n",
        "            Items IDs in current session.\n",
        "        k : Integer\n",
        "            How many items to recommend\n",
        "        Returns\n",
        "        --------\n",
        "        out : pandas.Series\n",
        "            Prediction scores for selected items on how likely to be the next item of this session. \n",
        "            Indexed by the item IDs.\n",
        "        '''\n",
        "            \n",
        "        all_len = len(self.predict_for_item_ids)\n",
        "        input_item_id = session_items[-1]\n",
        "        neighbors = self.find_neighbors(input_item_id, session_items)\n",
        "        scores = self.score_items(neighbors, session_items)\n",
        "        \n",
        "        # Create things in the format ..\n",
        "        preds = np.zeros(all_len)\n",
        "        scores_keys = list(scores.keys())\n",
        "        for i in range(all_len):\n",
        "            if i+1 in scores_keys:\n",
        "                preds[i] = scores[i+1]\n",
        "                \n",
        "        series = pd.Series(data = preds, index = self.predict_for_item_ids)\n",
        "        series = series / series.max()\n",
        "        return series.nlargest(k).index.values\n",
        "    \n",
        "    def items_for_session(self, session):\n",
        "        '''\n",
        "        Returns all items in the session\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        session: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : set           \n",
        "        '''\n",
        "        return self.session_item_map.get(session);\n",
        "    \n",
        "    def vec_for_session(self, session):\n",
        "        '''\n",
        "        Returns all items in the session\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        session: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : set           \n",
        "        '''\n",
        "        return self.session_vec_map.get(session);\n",
        "    \n",
        "    def sessions_for_item(self, item_id):\n",
        "        '''\n",
        "        Returns all session for an item\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        item: Id of the item session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : set           \n",
        "        '''\n",
        "        return self.item_session_map.get( item_id ) if item_id in self.item_session_map else set()\n",
        "        \n",
        "        \n",
        "    def most_recent_sessions( self, sessions, number ):\n",
        "        '''\n",
        "        Find the most recent sessions in the given set\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        sessions: set of session ids\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : set           \n",
        "        '''\n",
        "        sample = set()\n",
        "\n",
        "        tuples = list()\n",
        "        for session in sessions:\n",
        "            time = self.session_time.get( session )\n",
        "            if time is None:\n",
        "                print(' EMPTY TIMESTAMP!! ', session)\n",
        "            tuples.append((session, time))\n",
        "            \n",
        "        tuples = sorted(tuples, key=itemgetter(1), reverse=True)\n",
        "        #print 'sorted list ', sortedList\n",
        "        cnt = 0\n",
        "        for element in tuples:\n",
        "            cnt = cnt + 1\n",
        "            if cnt > number:\n",
        "                break\n",
        "            sample.add( element[0] )\n",
        "        #print 'returning sample of size ', len(sample)\n",
        "        return sample\n",
        "        \n",
        "        \n",
        "    def possible_neighbor_sessions(self, input_item_id):\n",
        "        '''\n",
        "        Find a set of session to later on find neighbors in.\n",
        "        A self.sample_size of 0 uses all sessions in which any item of the current session appears. \n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        sessions: set of session ids\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : set           \n",
        "        '''\n",
        "        \n",
        "        self.relevant_sessions = self.relevant_sessions | self.sessions_for_item( input_item_id )\n",
        "               \n",
        "        if self.sample_size == 0: #use all session as possible neighbors\n",
        "            return self.relevant_sessions\n",
        "\n",
        "        else: #sample some sessions\n",
        "            if len(self.relevant_sessions) > self.sample_size:    \n",
        "                return self.relevant_sessions[-self.sample_size:]\n",
        "            else: \n",
        "                return self.relevant_sessions\n",
        "                        \n",
        "    def calc_similarity(self, session_items, sessions):\n",
        "        '''\n",
        "        Calculates the configured similarity for the items in session_items and each session in sessions.\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        session_items: set of item ids\n",
        "        sessions: list of session ids\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : list of tuple (session_id,similarity)           \n",
        "        '''\n",
        "        pos_map = {}\n",
        "        length = len(session_items)\n",
        "        \n",
        "        count = 1\n",
        "        for item in session_items:\n",
        "            if self.weighting is not None: \n",
        "                pos_map[item] = getattr(self, self.weighting)(count, length)\n",
        "                count += 1\n",
        "            else:\n",
        "                pos_map[item] = 1\n",
        "        #print('POS MAP: ', pos_map, session_items)\n",
        "        items = set(session_items)\n",
        "        neighbors = []\n",
        "        for session in sessions: \n",
        "            n_items = self.items_for_session(session)\n",
        "            similarity = self.vec(items, n_items, pos_map)        \n",
        "            if similarity > 0:\n",
        "                neighbors.append((session, similarity))\n",
        "        return neighbors\n",
        "\n",
        "    #-----------------\n",
        "    # Find a set of neighbors, returns a list of tuples (sessionid: similarity) \n",
        "    #-----------------\n",
        "    def find_neighbors( self, input_item_id, session_items):\n",
        "        '''\n",
        "        Finds the k nearest neighbors for the given session_id and the current item input_item_id. \n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        session_items: list of item ids in current session\n",
        "        input_item_id: int\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : list of tuple (session_id, similarity)           \n",
        "        '''\n",
        "        #print('SESSION ITEMS1:', session_items)\n",
        "        possible_neighbors = self.possible_neighbor_sessions(input_item_id)\n",
        "        possible_neighbors = self.calc_similarity(session_items, possible_neighbors)\n",
        "        \n",
        "        possible_neighbors = sorted( possible_neighbors, reverse=True, key=lambda x: x[1] )\n",
        "        possible_neighbors = possible_neighbors[:self.k]\n",
        "        \n",
        "        return possible_neighbors\n",
        "    \n",
        "            \n",
        "    def score_items(self, neighbors, current_session):\n",
        "        '''\n",
        "        Compute a set of scores for all items given a set of neighbors.\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        neighbors: set of session ids\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : list of tuple (item, score)           \n",
        "        '''\n",
        "        # now we have the set of relevant items to make predictions\n",
        "        scores = dict()\n",
        "        # iterate over the sessions\n",
        "        for session in neighbors:\n",
        "            # get the items in this session\n",
        "            items = self.items_for_session( session[0] )\n",
        "            step = 1\n",
        "            \n",
        "            for item in reversed( current_session ):\n",
        "                if item in items:\n",
        "                    decay = getattr(self, self.weighting_score)(step)\n",
        "                    break\n",
        "                step += 1\n",
        "                                    \n",
        "            for item in items:\n",
        "                old_score = scores.get( item )\n",
        "                similarity = session[1]\n",
        "                \n",
        "                if old_score is None:\n",
        "                    scores.update({item : ( similarity * decay ) })\n",
        "                else: \n",
        "                    new_score = old_score + ( similarity * decay )\n",
        "                    scores.update({item : new_score})\n",
        "                    \n",
        "        return scores\n",
        "    \n",
        "    \n",
        "    def linear_score(self, i):\n",
        "        return 1 - (0.1*i) if i <= 100 else 0\n",
        "    \n",
        "    def same_score(self, i):\n",
        "        return 1\n",
        "    \n",
        "    def div_score(self, i):\n",
        "        return 1/i\n",
        "    \n",
        "    def log_score(self, i):\n",
        "        return 1/(log10(i+1.7))\n",
        "    \n",
        "    def quadratic_score(self, i):\n",
        "        return 1/(i*i)\n",
        "    \n",
        "    def linear(self, i, length):\n",
        "        return 1 - (0.1*(length-i)) if i <= 10 else 0\n",
        "    \n",
        "    def same(self, i, length):\n",
        "        return 1\n",
        "    \n",
        "    def div(self, i, length):\n",
        "        return i/length\n",
        "    \n",
        "    def log(self, i, length):\n",
        "        return 1/(log10((length-i)+1.7))\n",
        "    \n",
        "    def quadratic(self, i, length):\n",
        "        return (i/length)**2\n",
        "\n",
        "\n",
        "    def jaccard(self, first, second):\n",
        "        '''\n",
        "        Calculates the jaccard index for two sessions\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        first: Id of a session\n",
        "        second: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : float value           \n",
        "        '''\n",
        "        sc = time.clock()\n",
        "        intersection = len(first & second)\n",
        "        union = len(first | second )\n",
        "        res = intersection / union\n",
        "        \n",
        "        self.sim_time += (time.clock() - sc)\n",
        "        \n",
        "        return res \n",
        "    \n",
        "    def cosine(self, first, second):\n",
        "        '''\n",
        "        Calculates the cosine similarity for two sessions\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        first: Id of a session\n",
        "        second: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : float value           \n",
        "        '''\n",
        "        li = len(first&second)\n",
        "        la = len(first)\n",
        "        lb = len(second)\n",
        "        result = li / sqrt(la) * sqrt(lb)\n",
        "\n",
        "        return result\n",
        "    \n",
        "    def tanimoto(self, first, second):\n",
        "        '''\n",
        "        Calculates the cosine tanimoto similarity for two sessions\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        first: Id of a session\n",
        "        second: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : float value           \n",
        "        '''\n",
        "        li = len(first&second)\n",
        "        la = len(first)\n",
        "        lb = len(second)\n",
        "        result = li / ( la + lb -li )\n",
        "\n",
        "        return result\n",
        "    \n",
        "    def binary(self, first, second):\n",
        "        '''\n",
        "        Calculates the ? for 2 sessions\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        first: Id of a session\n",
        "        second: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : float value           \n",
        "        '''\n",
        "        a = len(first&second)\n",
        "        b = len(first)\n",
        "        c = len(second)\n",
        "        \n",
        "        result = (2 * a) / ((2 * a) + b + c)\n",
        "\n",
        "        return result\n",
        "    \n",
        "    def vec(self, first, second, map):\n",
        "        '''\n",
        "        Calculates the ? for 2 sessions\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        first: Id of a session\n",
        "        second: Id of a session\n",
        "        \n",
        "        Returns \n",
        "        --------\n",
        "        out : float value           \n",
        "        '''\n",
        "        a = first & second\n",
        "        sum = 0\n",
        "        for i in a:\n",
        "            sum += map[i]\n",
        "        \n",
        "        result = sum / len(map)\n",
        "\n",
        "        return result    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2Zfq4EKCb_o"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# from recohut.utils.common_utils import download_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPTgJ13WDbGn"
      },
      "outputs": [],
      "source": [
        "# Cell\n",
        "\n",
        "# Cell\n",
        "import sys\n",
        "import os\n",
        "import ssl\n",
        "import os.path as osp\n",
        "from six.moves import urllib\n",
        "import errno\n",
        "import tarfile\n",
        "import zipfile\n",
        "import bz2\n",
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# Internal Cell\n",
        "def makedirs(path):\n",
        "    try:\n",
        "        os.makedirs(osp.expanduser(osp.normpath(path)))\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST and osp.isdir(path):\n",
        "            raise \n",
        "            \n",
        "def wget_download(url, savepath):\n",
        "    import wget\n",
        "    wget.download(url, str(savepath))\n",
        "\n",
        "# Cell\n",
        "def download_url(url: str, folder: str, log: bool = True):\n",
        "    r\"\"\"Downloads the content of an URL to a specific folder.\n",
        "    Args:\n",
        "        url (string): The url.\n",
        "        folder (string): The folder.\n",
        "        log (bool, optional): If :obj:`False`, will not print anything to the\n",
        "            console. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "\n",
        "    filename = url.rpartition('/')[2]\n",
        "    filename = filename if filename[0] == '?' else filename.split('?')[0]\n",
        "    path = osp.join(folder, filename)\n",
        "\n",
        "    if osp.exists(path):  # pragma: no cover\n",
        "        if log:\n",
        "            print(f'Using existing file {filename}', file=sys.stderr)\n",
        "        return path\n",
        "\n",
        "    if log:\n",
        "        print(f'Downloading {url}', file=sys.stderr)\n",
        "\n",
        "    \n",
        "    (folder)\n",
        "\n",
        "    context = ssl._create_unverified_context()\n",
        "    data = urllib.request.urlopen(url, context=context)\n",
        "\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(data.read())\n",
        "\n",
        "    return path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucHKoeSCDp7Y"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn8ht8TMDuD0",
        "outputId": "e50813ac-1a78-47b1-cd9d-5eaa4586c818"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data\t\t    yoochoose-buys.dat\t  yoochoose-test.dat\n",
            "dataset-README.txt  yoochoose-clicks.dat\n",
            "sample_data\t    yoochoose-data.7z\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "dO0mQNvkCb_q",
        "outputId": "7c838c08-7bcc-4868-8b5c-365b9f78f95f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_train.txt\n",
            "Downloading https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_valid.txt\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/yoochoose_valid.txt'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_root = 'data/'\n",
        "download_url('https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_train.txt', data_root)\n",
        "download_url('https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_valid.txt', data_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "5uugR6DIKjlJ",
        "outputId": "38f6c33f-a80f-4d1e-dd80-b3526cccf6b9"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-c8cc228f0d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_valid' is not defined"
          ]
        }
      ],
      "source": [
        "#23934\n",
        "test_session = x_valid[x_valid['session_id'] == 23934]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRcNdG6oTeM9",
        "outputId": "0821bb9e-5cd9-4077-a8bb-b0d968af55ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2102695\n"
          ]
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--K', type=int, default=20, help=\"K items to be used in Recall@K and MRR@K\")\n",
        "parser.add_argument('--neighbors', type=int, default=200, help=\"K neighbors to be used in KNN\")\n",
        "parser.add_argument('--sample', type=int, default=0, help=\"Max Number of steps to walk back from the currently viewed item\")\n",
        "parser.add_argument('--weight_score', type=str, default='div_score', help=\"Decay function to lower the score of candidate items from a neighboring sessions that were selected by less recently clicked items in the current session. (linear, same, div, log, quadratic)_score\")\n",
        "parser.add_argument('--weighting', type=str, default='div', help=\"Decay function to determine the importance/weight of individual actions in the current session(linear, same, div, log, qudratic)\")\n",
        "parser.add_argument('--similarity', type=str, default='cosine', help=\"String to define the method for the similarity calculation (jaccard, cosine, binary, tanimoto). (default: cosine)\")\n",
        "parser.add_argument('--itemid', default='sid', type=str)\n",
        "parser.add_argument('--sessionid', default='uid', type=str)\n",
        "parser.add_argument('--valid_data', default='yoochoose_valid.txt', type=str)\n",
        "parser.add_argument('--train_data', default='yoochoose_train.txt', type=str)\n",
        "parser.add_argument('--data_folder', default=data_root, type=str)\n",
        "args = parser.parse_args([])\n",
        "\n",
        "\n",
        "# Get the arguments\n",
        "train_data = os.path.join(args.data_folder, args.train_data)\n",
        "x_train = pd.read_csv(train_data)\n",
        "print (len(x_train))\n",
        "#print (x_train)\n",
        "x_train.sort_values(args.sessionid, inplace=True)\n",
        "distinct_train = x_train[args.itemid].nunique()\n",
        "\n",
        "valid_data = os.path.join(args.data_folder, args.valid_data)\n",
        "x_valid = pd.read_csv(valid_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "lcJRi4N2Tmvo",
        "outputId": "3cb91a0b-9654-4f6d-f975-445c3137c5b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4d95546e-09cd-4e8e-83c3-1e3ab6e5fa59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uid</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>sid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411990e+09</td>\n",
              "      <td>214718160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411992e+09</td>\n",
              "      <td>214516142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214848596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214848384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214849314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214829765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214561475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214718160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214718160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214718160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214854924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214856546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214558258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214856546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411993e+09</td>\n",
              "      <td>214718160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411994e+09</td>\n",
              "      <td>214717888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411994e+09</td>\n",
              "      <td>214846125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411994e+09</td>\n",
              "      <td>214580351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411994e+09</td>\n",
              "      <td>214516147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>11267046</td>\n",
              "      <td>1.411994e+09</td>\n",
              "      <td>214846125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d95546e-09cd-4e8e-83c3-1e3ab6e5fa59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d95546e-09cd-4e8e-83c3-1e3ab6e5fa59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d95546e-09cd-4e8e-83c3-1e3ab6e5fa59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         uid     timestamp        sid\n",
              "0   11267046  1.411990e+09  214718160\n",
              "1   11267046  1.411992e+09  214516142\n",
              "2   11267046  1.411993e+09  214848596\n",
              "3   11267046  1.411993e+09  214848384\n",
              "4   11267046  1.411993e+09  214849314\n",
              "5   11267046  1.411993e+09  214829765\n",
              "6   11267046  1.411993e+09  214561475\n",
              "7   11267046  1.411993e+09  214718160\n",
              "8   11267046  1.411993e+09  214718160\n",
              "9   11267046  1.411993e+09  214718160\n",
              "10  11267046  1.411993e+09  214854924\n",
              "11  11267046  1.411993e+09  214856546\n",
              "12  11267046  1.411993e+09  214558258\n",
              "13  11267046  1.411993e+09  214856546\n",
              "14  11267046  1.411993e+09  214718160\n",
              "15  11267046  1.411994e+09  214717888\n",
              "16  11267046  1.411994e+09  214846125\n",
              "17  11267046  1.411994e+09  214580351\n",
              "18  11267046  1.411994e+09  214516147\n",
              "19  11267046  1.411994e+09  214846125"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_session = x_valid[x_valid['uid'] == 11267046]\n",
        "test_session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_P2tuLgT6ge"
      },
      "outputs": [],
      "source": [
        "#x_valid = test_session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8I4bvrMCb_r",
        "outputId": "1117f13d-abf8-4af8-ddfe-668dc8d79178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Reading Data \n",
            "Start Model Fitting...\n",
            "End Model Fitting\n",
            " Start Predictions...\n",
            "Finished Prediction for  100 items.\n",
            "Finished Prediction for  200 items.\n",
            "Finished Prediction for  300 items.\n",
            "Finished Prediction for  400 items.\n",
            "Finished Prediction for  500 items.\n",
            "Finished Prediction for  600 items.\n",
            "Finished Prediction for  700 items.\n",
            "Finished Prediction for  800 items.\n",
            "Finished Prediction for  900 items.\n",
            "Finished Prediction for  1000 items.\n",
            "Finished Prediction for  1100 items.\n",
            "Finished Prediction for  1200 items.\n",
            "Finished Prediction for  1300 items.\n",
            "Finished Prediction for  1400 items.\n",
            "Finished Prediction for  1500 items.\n",
            "Finished Prediction for  1600 items.\n",
            "Finished Prediction for  1700 items.\n",
            "Finished Prediction for  1800 items.\n",
            "Finished Prediction for  1900 items.\n",
            "Finished Prediction for  2000 items.\n",
            "Finished Prediction for  2100 items.\n",
            "Finished Prediction for  2200 items.\n",
            "Finished Prediction for  2300 items.\n",
            "Finished Prediction for  2400 items.\n",
            "Finished Prediction for  2500 items.\n",
            "Finished Prediction for  2600 items.\n",
            "Finished Prediction for  2700 items.\n",
            "Finished Prediction for  2800 items.\n",
            "Finished Prediction for  2900 items.\n",
            "Finished Prediction for  3000 items.\n",
            "Finished Prediction for  3100 items.\n",
            "Finished Prediction for  3200 items.\n",
            "Finished Prediction for  3300 items.\n",
            "Finished Prediction for  3400 items.\n",
            "Finished Prediction for  3500 items.\n",
            "Finished Prediction for  3600 items.\n",
            "Finished Prediction for  3700 items.\n",
            "Finished Prediction for  3800 items.\n",
            "Finished Prediction for  3900 items.\n",
            "Finished Prediction for  4000 items.\n",
            "Finished Prediction for  4100 items.\n",
            "Finished Prediction for  4200 items.\n",
            "Finished Prediction for  4300 items.\n",
            "Finished Prediction for  4400 items.\n",
            "Finished Prediction for  4500 items.\n",
            "Finished Prediction for  4600 items.\n",
            "Finished Prediction for  4700 items.\n",
            "Finished Prediction for  4800 items.\n",
            "Finished Prediction for  4900 items.\n",
            "Finished Prediction for  5000 items.\n",
            "Finished Prediction for  5100 items.\n",
            "Finished Prediction for  5200 items.\n",
            "Finished Prediction for  5300 items.\n",
            "Finished Prediction for  5400 items.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "x_valid.sort_values(args.sessionid, inplace=True)\n",
        "\n",
        "print('Finished Reading Data \\nStart Model Fitting...')\n",
        "# Fitting Model\n",
        "t1 = time.time()\n",
        "model = VMContextKNN(k = args.neighbors, sample_size = args.sample, similarity = args.similarity, \n",
        "\t\t\t\t\t weighting = args.weighting, weighting_score = args.weight_score,\n",
        "\t\t\t\t\t session_key = args.sessionid, item_key = args.itemid)\n",
        "model.fit(x_train)\n",
        "#memory_task.kill()\n",
        "train_time = time.time() - t1\n",
        "print('End Model Fitting\\n Start Predictions...')\n",
        "\n",
        "# Test Set Evaluation\n",
        "test_size = 0.0\n",
        "hit = [0.0]\n",
        "MRR = [0.0]\n",
        "cov = [[]]\n",
        "pop = [[]]\n",
        "Ks = [args.K]\n",
        "cur_length = 0\n",
        "cur_session = -1\n",
        "last_items = []\n",
        "t1 = time.time()\n",
        "index_item = x_valid.columns.get_loc(args.itemid)\n",
        "index_session = x_valid.columns.get_loc(args.sessionid)\n",
        "train_items = model.items_ids\n",
        "counter = 0\n",
        "for row in x_valid.itertuples( index=False ):\n",
        "\tcounter += 1\n",
        "\tif counter % 100 == 0:\n",
        "\t\tprint('Finished Prediction for ', counter, 'items.')\n",
        "\tsession_id, item_id = row[index_session], row[index_item]\n",
        "\tif session_id != cur_session:\n",
        "\t\tcur_session = session_id\n",
        "\t\tlast_items = []\n",
        "\t\tcur_length = 0\n",
        "\t\n",
        "\tif not item_id in last_items and item_id in train_items:\n",
        "\t\t#print(item_id, item_id in train_items)\n",
        "\t\titem_id = model.old_new[item_id]\n",
        "\t\tif len(last_items) > cur_length: #make prediction\n",
        "\t\t\tcur_length += 1\n",
        "\t\t\ttest_size += 1\n",
        "\t\t\t# Predict the most similar items to items\n",
        "\t\t\tfor k in range(len(Ks)):\n",
        "\t\t\t\tpredictions = model.predict_next(last_items, k = Ks[k])\n",
        "\t\t\t\t# Evaluation\n",
        "\t\t\t\trank = 0\n",
        "\t\t\t\tfor predicted_item in predictions:\n",
        "\t\t\t\t\tif predicted_item not in cov[k]:\n",
        "\t\t\t\t\t\tcov[k].append(predicted_item)\n",
        "\t\t\t\t\tpop[k].append(model.freqs[predicted_item])\n",
        "\t\t\t\t\trank += 1\n",
        "\t\t\t\t\tif predicted_item == item_id:\n",
        "\t\t\t\t\t\thit[k] += 1.0\n",
        "\t\t\t\t\t\tMRR[k] += 1/rank\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\n",
        "\t\tlast_items.append(item_id)\n",
        "  \n",
        "#memory_task.kill()\n",
        "hit[:] = [x / test_size for x in hit]\n",
        "MRR[:] = [x / test_size for x in MRR]\n",
        "cov[:] = [len(x) / distinct_train for x in cov]\n",
        "maxi = max(model.freqs.values())\n",
        "pop[:] = [np.mean(x) / maxi for x in pop]\n",
        "test_time = (time.time() - t1)\n",
        "print('Recall:', hit)\n",
        "print ('\\nMRR:', MRR)\n",
        "print ('\\nCoverage:', cov)\n",
        "print ('\\nPopularity:', pop)\n",
        "print ('\\ntrain_time:', train_time)\n",
        "print ('\\ntest_time:', test_time)\n",
        "print('End Model Predictions')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckYlhpYuUGJh"
      },
      "outputs": [],
      "source": [
        "Recall: [0.21052631578947367]\n",
        "\n",
        "MRR: [0.10526315789473684]\n",
        "\n",
        "Coverage: [0.00108679901463556]\n",
        "\n",
        "Popularity: [0.08503564848193543]\n",
        "\n",
        "train_time: 3.417477607727051\n",
        "\n",
        "test_time: 0.7278115749359131\n",
        "End Model Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g3KhQ_PCb_s"
      },
      "source": [
        "> **References:-**\n",
        "- [https://arxiv.org/pdf/1803.09587.pdf](https://arxiv.org/pdf/1803.09587.pdf)\n",
        "- [https://github.com/mmaher22/iCV-SBR/tree/master/Source Codes/VSKNN_Python](https://github.com/mmaher22/iCV-SBR/tree/master/Source%20Codes/VSKNN_Python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isg442FWCb_t"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x8RnyP4ABqHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ay9ahrwCBqKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yZiHxXAvBqNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N7jsl8KXBqPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wQYH7Q3CBqSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SR\n"
      ],
      "metadata": {
        "id": "5sTJ5JfXB0ZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class SequentialRules: \n",
        "    '''\n",
        "    SequentialRules(steps = 10, weighting='div', pruning=20.0, session_key='SessionId', item_keys=['ItemId'])\n",
        "        \n",
        "    Parameters\n",
        "    --------\n",
        "    pruning : int\n",
        "        Prune the results per item to a list of the top N co-occurrences. (Default value: 10)\n",
        "    session_key : string\n",
        "        The data frame key for the session identifier. (Default value: SessionId)\n",
        "    item_keys : string\n",
        "        The data frame list of keys for the item identifier as first item in list \n",
        "        and features keys next. (Default value: [ItemID])    \n",
        "    steps : int\n",
        "        Number of steps to walk back from the currently viewed item. (Default value: 10)\n",
        "    weighting : string\n",
        "        Weighting function for the previous items (linear, same, div, log, qudratic). (Default value: div)\n",
        "    pruning : int\n",
        "        Prune the results per item to a list of the top N sequential co-occurrences. (Default value: 20). \n",
        "    '''\n",
        "    \n",
        "    def __init__( self, steps = 10, weighting='div', pruning=20, \n",
        "                 session_key='SessionID', item_keys=['ItemId']):\n",
        "        self.steps = steps\n",
        "        self.pruning = pruning\n",
        "        self.weighting = weighting\n",
        "        self.session_key = session_key\n",
        "        self.item_keys = item_keys\n",
        "        self.items_features = {}\n",
        "        self.predict_for_item_ids = []\n",
        "        self.session = -1\n",
        "        self.session_items = []\n",
        "            \n",
        "    def fit( self, train):\n",
        "        '''\n",
        "        Trains the predictor.\n",
        "        \n",
        "        Parameters\n",
        "        --------\n",
        "        data: pandas.DataFrame\n",
        "            Training data. It contains the transactions of the sessions. \n",
        "            It has one column for session IDs, one for item IDs and many for the\n",
        "            item features if exist.\n",
        "            It must have a header. Column names are arbitrary, but must \n",
        "            correspond to the ones you set during the initialization of the \n",
        "            network (session_key, item_keys).\n",
        "        '''\n",
        "        cur_session = -1\n",
        "        last_items = []\n",
        "        all_rules = []\n",
        "        indices_item = []\n",
        "        for i in self.item_keys:\n",
        "            all_rules.append(dict())\n",
        "            indices_item.append( train.columns.get_loc(i) )\n",
        "            \n",
        "        train.sort_values(self.session_key, inplace=True)\n",
        "        index_session = train.columns.get_loc(self.session_key)\n",
        "        \n",
        "        #Create Dictionary of items and their features\n",
        "        for row in train.itertuples( index=False ):\n",
        "            item_id = row[indices_item[0]]\n",
        "            if not item_id in self.items_features.keys() :\n",
        "                self.items_features[item_id] = []\n",
        "                for i in indices_item:\n",
        "                    self.items_features[item_id].append(row[i])\n",
        "        \n",
        "        for i in range(len(self.item_keys)):\n",
        "            rules = all_rules[i]\n",
        "            index_item = indices_item[i] #which feature of the items to work on\n",
        "            for row in train.itertuples( index=False ):\n",
        "                session_id, item_id = row[index_session], row[index_item]\n",
        "                if session_id != cur_session:\n",
        "                    cur_session = session_id\n",
        "                    last_items = []\n",
        "                else: \n",
        "                    for j in range( 1, self.steps+1 if len(last_items) >= self.steps else len(last_items)+1 ):\n",
        "                        prev_item = last_items[-j]   \n",
        "                        if not prev_item in rules :\n",
        "                            rules[prev_item] = dict()        \n",
        "                        if not item_id in rules[prev_item]:\n",
        "                            rules[prev_item][item_id] = 0\n",
        "                        \n",
        "                        rules[prev_item][item_id] += getattr(self, self.weighting)( j )\n",
        "                        \n",
        "                last_items.append(item_id)\n",
        "                \n",
        "            if self.pruning > 0 :\n",
        "                rules = self.prune( rules )\n",
        "            \n",
        "            all_rules[i] = rules\n",
        "        \n",
        "        self.all_rules = all_rules\n",
        "        self.predict_for_item_ids = list(self.all_rules[0].keys())\n",
        "    \n",
        "    def linear(self, i):\n",
        "        return 1 - (0.1*i) if i <= 100 else 0\n",
        "    \n",
        "    def same(self, i):\n",
        "        return 1\n",
        "    \n",
        "    def div(self, i):\n",
        "        return 1/i\n",
        "    \n",
        "    def log(self, i):\n",
        "        return 1/(log10(i+1.7))\n",
        "    \n",
        "    def quadratic(self, i):\n",
        "        return 1/(i*i)\n",
        "    \n",
        "    def predict_next(self, session_items, k = 20):\n",
        "        '''\n",
        "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
        "                \n",
        "        Parameters\n",
        "        --------\n",
        "        session_items : List\n",
        "            Items IDs in current session.\n",
        "        k : Integer\n",
        "            How many items to recommend\n",
        "        Returns\n",
        "        --------\n",
        "        out : pandas.Series\n",
        "            Prediction scores for selected items on how likely to be the next item of this session. \n",
        "            Indexed by the item IDs.\n",
        "        \n",
        "        '''\n",
        "        all_len = len(self.predict_for_item_ids)\n",
        "        input_item_id = session_items[-1]\n",
        "        preds = np.zeros( all_len ) \n",
        "             \n",
        "        if input_item_id in self.all_rules[0].keys():\n",
        "            for k_ind in range(all_len):\n",
        "                key = self.predict_for_item_ids[k_ind]\n",
        "                if key in session_items:\n",
        "                    continue\n",
        "                try:\n",
        "                    preds[ k_ind ] += self.all_rules[0][input_item_id][key]\n",
        "                except:\n",
        "                    pass\n",
        "                for i in range(1, len(self.all_rules)):\n",
        "                    input_item_feature = self.items_features[input_item_id][i]\n",
        "                    key_feature = self.items_features[key][i]\n",
        "                    try:\n",
        "                        preds[ k_ind ] += self.all_rules[i][input_item_feature][key_feature]\n",
        "                    except:\n",
        "                        pass\n",
        "        \n",
        "        series = pd.Series(data=preds, index=self.predict_for_item_ids)\n",
        "        series = series / series.max()\n",
        "        \n",
        "        return series.nlargest(k).index.values\n",
        "    \n",
        "    def prune(self, rules): \n",
        "        '''\n",
        "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
        "        Parameters\n",
        "            --------\n",
        "            rules : dict of dicts\n",
        "                The rules mined from the training data\n",
        "        '''\n",
        "        for k1 in rules:\n",
        "            tmp = rules[k1]\n",
        "            if self.pruning < 1:\n",
        "                keep = len(tmp) - int( len(tmp) * self.pruning )\n",
        "            elif self.pruning >= 1:\n",
        "                keep = self.pruning\n",
        "            counter = col.Counter( tmp )\n",
        "            rules[k1] = dict()\n",
        "            for k2, v in counter.most_common( keep ):\n",
        "                rules[k1][k2] = v\n",
        "        return rules"
      ],
      "metadata": {
        "id": "1QVGOzZQB3Xo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell\n",
        "import sys\n",
        "import os\n",
        "import ssl\n",
        "import os.path as osp\n",
        "from six.moves import urllib\n",
        "import errno\n",
        "import tarfile\n",
        "import zipfile\n",
        "import bz2\n",
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# Internal Cell\n",
        "def makedirs(path):\n",
        "    try:\n",
        "        os.makedirs(osp.expanduser(osp.normpath(path)))\n",
        "    except OSError as e:\n",
        "        if e.errno != errno.EEXIST and osp.isdir(path):\n",
        "            raise e\n",
        "\n",
        "# Cell\n",
        "def wget_download(url, savepath):\n",
        "    import wget\n",
        "    wget.download(url, str(savepath))\n",
        "\n",
        "# Cell\n",
        "def download_url(url: str, folder: str, log: bool = True):\n",
        "    r\"\"\"Downloads the content of an URL to a specific folder.\n",
        "    Args:\n",
        "        url (string): The url.\n",
        "        folder (string): The folder.\n",
        "        log (bool, optional): If :obj:`False`, will not print anything to the\n",
        "            console. (default: :obj:`True`)\n",
        "    \"\"\"\n",
        "\n",
        "    filename = url.rpartition('/')[2]\n",
        "    filename = filename if filename[0] == '?' else filename.split('?')[0]\n",
        "    path = osp.join(folder, filename)\n",
        "\n",
        "    if osp.exists(path):  # pragma: no cover\n",
        "        if log:\n",
        "            print(f'Using existing file {filename}', file=sys.stderr)\n",
        "        return path\n",
        "\n",
        "    if log:\n",
        "        print(f'Downloading {url}', file=sys.stderr)\n",
        "\n",
        "    makedirs(folder)\n",
        "\n",
        "    context = ssl._create_unverified_context()\n",
        "    data = urllib.request.urlopen(url, context=context)\n",
        "\n",
        "    with open(path, 'wb') as f:\n",
        "        f.write(data.read())\n",
        "\n",
        "    return path\n",
        "\n",
        "\n",
        "data_root = '/content/data'\n",
        "download_url('https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_train.txt', data_root)\n",
        "download_url('https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_valid.txt', data_root)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "qz7TI1KLDeOE",
        "outputId": "6339a762-4a27-46c7-afe8-ab2a6d7c5131"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_train.txt\n",
            "Downloading https://github.com/RecoHut-Datasets/yoochoose/raw/v4/yoochoose_valid.txt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/data/yoochoose_valid.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--prune', type=int, default=0, help=\"Association Rules Pruning Parameter\")\n",
        "parser.add_argument('--K', type=int, default=20, help=\"K items to be used in Recall@K and MRR@K\")\n",
        "parser.add_argument('--steps', type=int, default=10, help=\"Max Number of steps to walk back from the currently viewed item\")\n",
        "parser.add_argument('--weighting', type=str, default='div', help=\"Weighting function for the previous items (linear, same, div, log, qudratic)\")\n",
        "parser.add_argument('--itemid', default='sid', type=str)\n",
        "parser.add_argument('--sessionid', default='uid', type=str)\n",
        "parser.add_argument('--item_feats', default='', type=str, \n",
        "                    help=\"Names of Columns containing items features separated by #\")\n",
        "parser.add_argument('--valid_data', default='yoochoose_valid.txt', type=str)\n",
        "parser.add_argument('--train_data', default='yoochoose_train.txt', type=str)\n",
        "parser.add_argument('--data_folder', default=data_root, type=str)\n",
        "\n",
        "# Get the arguments\n",
        "args = parser.parse_args([])\n",
        "train_data = os.path.join(args.data_folder, args.train_data)\n",
        "x_train = pd.read_csv(train_data)\n",
        "valid_data = os.path.join(args.data_folder, args.valid_data)\n",
        "x_valid = pd.read_csv(valid_data)\n",
        "x_valid = x_valid[0:50]\n",
        "x_valid.sort_values(args.sessionid, inplace=True)\n",
        "\n",
        "items_feats = [args.itemid]\n",
        "ffeats = args.item_feats.strip().split(\"#\")\n",
        "if ffeats[0] != '':\n",
        "    items_feats.extend(ffeats)\n",
        "\n",
        "print('Finished Reading Data \\nStart Model Fitting...')\n",
        "# Fitting AR Model\n",
        "t1 = time.time()\n",
        "model = SequentialRules(session_key = args.sessionid, item_keys = items_feats, \n",
        "                        pruning=args.prune, steps=args.steps, weighting=args.weighting)\n",
        "model.fit(x_train)\n",
        "t2 = time.time()\n",
        "print('End Model Fitting with total time =', t2 - t1, '\\n Start Predictions...')\n",
        "\n",
        "# Test Set Evaluation\n",
        "test_size = 0.0\n",
        "hit = 0.0\n",
        "MRR = 0.0\n",
        "cur_length = 0\n",
        "cur_session = -1\n",
        "last_items = []\n",
        "t1 = time.time()\n",
        "index_item = x_valid.columns.get_loc(args.itemid)\n",
        "index_session = x_valid.columns.get_loc(args.sessionid)\n",
        "train_items = model.items_features.keys()\n",
        "counter = 0\n",
        "for row in x_valid.itertuples( index=False ):\n",
        "    counter += 1\n",
        "    if counter % 5000 == 0:\n",
        "        print('Finished Prediction for ', counter, 'items.')\n",
        "    session_id, item_id = row[index_session], row[index_item]\n",
        "    if session_id != cur_session:\n",
        "        cur_session = session_id\n",
        "        last_items = []\n",
        "        cur_length = 0\n",
        "    \n",
        "    if not item_id in last_items and item_id in train_items:\n",
        "        if len(last_items) > cur_length: #make prediction\n",
        "            cur_length += 1\n",
        "            test_size += 1\n",
        "            # Predict the most similar items to items\n",
        "            predictions = model.predict_next(last_items, k = args.K)\n",
        "            #print('preds:', predictions)\n",
        "            # Evaluation\n",
        "            rank = 0\n",
        "            for predicted_item in predictions:\n",
        "                rank += 1\n",
        "                if predicted_item == item_id:\n",
        "                    hit += 1.0\n",
        "                    MRR += 1/rank\n",
        "                    break\n",
        "        \n",
        "        last_items.append(item_id)\n",
        "t2 = time.time()\n",
        "print('Recall: {}'.format(hit / test_size))\n",
        "print ('\\nMRR: {}'.format(MRR / test_size))\n",
        "print('End Model Predictions with total time =', t2 - t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA5W1qt8B3aN",
        "outputId": "45c06e42-fa57-4fed-877a-a0d624d750a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Reading Data \n",
            "Start Model Fitting...\n",
            "End Model Fitting with total time = 18.449315547943115 \n",
            " Start Predictions...\n",
            "Recall: 0.5294117647058824\n",
            "\n",
            "MRR: 0.14003648696555268\n",
            "End Model Predictions with total time = 0.5901572704315186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VV4QY7DrCVMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spop"
      ],
      "metadata": {
        "id": "9asU6q-7IyIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export\n",
        "class SessionPop:\n",
        "    '''\n",
        "    SessionPop(top_n=100, item_key='ItemId', support_by_key=None)\n",
        "    Session popularity predictor that gives higher scores to items with higher number of occurrences in the session. \n",
        "    Ties are broken up by adding the popularity score of the item.\n",
        "    The score is given by:\n",
        "    .. math::\n",
        "        r_{s,i} = supp_{s,i} + \\\\frac{supp_i}{(1+supp_i)}\n",
        "    Parameters\n",
        "    --------\n",
        "    top_n : int\n",
        "        Only give back non-zero scores to the top N ranking items. Should be higher or equal than the cut-off of your evaluation. (Default value: 100)\n",
        "    item_key : string\n",
        "        The header of the item IDs in the training data. (Default value: 'ItemId')\n",
        "    '''    \n",
        "    def __init__(self, top_n = 1000, session_key = 'SessionId', item_key = 'ItemId'):\n",
        "        self.top_n = top_n\n",
        "        self.item_key = item_key\n",
        "        self.session_id = session_key\n",
        "        \n",
        "    def fit(self, data):\n",
        "        '''\n",
        "        Trains the predictor.\n",
        "        Parameters\n",
        "        --------\n",
        "        data: pandas.DataFrame\n",
        "            Training data. It contains the transactions of the sessions. \n",
        "            It has one column for session IDs, one for item IDs.\n",
        "        '''\n",
        "        self.items = data[self.item_key].unique()\n",
        "        grp = data.groupby(self.item_key)\n",
        "        self.pop_list = grp.size()\n",
        "        self.pop_list = self.pop_list / (self.pop_list + 1)\n",
        "        self.pop_list.sort_values(ascending=False, inplace=True)\n",
        "        self.pop_list = self.pop_list.head(self.top_n)\n",
        "        self.prev_session_id = -1\n",
        "         \n",
        "    def predict_next(self, last_items, k):\n",
        "        '''\n",
        "        Gives predicton scores for a selected set of items on how likely they be the next item in the session.\n",
        "        Parameters\n",
        "        --------\n",
        "        last_items : list of items clicked in current session\n",
        "        k : number of items to recommend and evaluate based on it\n",
        "        Returns\n",
        "        --------\n",
        "        out : pandas.Series\n",
        "            Prediction scores for selected items on how likely to be the next item of this session. Indexed by the item IDs.\n",
        "        '''\n",
        "        pers = {}\n",
        "        for i in last_items:\n",
        "            pers[i] = pers[i] + 1 if i in pers.keys() else  1\n",
        "        \n",
        "        preds = np.zeros(len(self.items))\n",
        "        mask = np.in1d(self.items, self.pop_list.index)\n",
        "        ser = pd.Series(pers)\n",
        "        preds[mask] = self.pop_list[self.items[mask]]\n",
        "        \n",
        "        mask = np.in1d(self.items, ser.index)\n",
        "        preds[mask] += ser[self.items[mask]]\n",
        "        \n",
        "        series = pd.Series(data=preds, index=self.items)\n",
        "        series = series / series.max()    \n",
        "        return series.nlargest(k).index.values"
      ],
      "metadata": {
        "id": "smc8TW99B3cz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--K', type=int, default=20, help=\"K items to be used in Recall@K and MRR@K\")\n",
        "parser.add_argument('--topn', type=int, default=100, help=\"Number of top items to return non zero scores for them (most popular)\")\n",
        "parser.add_argument('--itemid', default='sid', type=str)\n",
        "parser.add_argument('--sessionid', default='uid', type=str)\n",
        "parser.add_argument('--valid_data', default='yoochoose_valid.txt', type=str)\n",
        "parser.add_argument('--train_data', default='yoochoose_train.txt', type=str)\n",
        "parser.add_argument('--data_folder', default=data_root, type=str)\n",
        "\n",
        "# Get the arguments\n",
        "args = parser.parse_args([])\n",
        "train_data = os.path.join(args.data_folder, args.train_data)\n",
        "x_train = pd.read_csv(train_data)\n",
        "valid_data = os.path.join(args.data_folder, args.valid_data)\n",
        "x_valid = pd.read_csv(valid_data)\n",
        "x_valid.sort_values(args.sessionid, inplace=True)\n",
        "x_valid = x_valid[0:50]\n",
        "print('Finished Reading Data \\nStart Model Fitting...')\n",
        "# Fitting AR Model\n",
        "t1 = time.time()\n",
        "model = SessionPop(top_n = args.topn, session_key = args.sessionid, item_key = args.itemid)\n",
        "model.fit(x_train)\n",
        "t2 = time.time()\n",
        "print('End Model Fitting with total time =', t2 - t1, '\\n Start Predictions...')\n",
        "\n",
        "# Test Set Evaluation\n",
        "test_size = 0.0\n",
        "hit = 0.0\n",
        "MRR = 0.0\n",
        "cur_length = 0\n",
        "cur_session = -1\n",
        "last_items = []\n",
        "t1 = time.time()\n",
        "index_item = x_valid.columns.get_loc(args.itemid)\n",
        "index_session = x_valid.columns.get_loc(args.sessionid)\n",
        "train_items = model.items\n",
        "counter = 0\n",
        "for row in x_valid.itertuples( index=False ):\n",
        "    counter += 1\n",
        "    if counter % 5000 == 0:\n",
        "        print('Finished Prediction for ', counter, 'items.')\n",
        "    session_id, item_id = row[index_session], row[index_item]\n",
        "    if session_id != cur_session:\n",
        "        cur_session = session_id\n",
        "        last_items = []\n",
        "        cur_length = 0\n",
        "    \n",
        "    if item_id in train_items:\n",
        "        if len(last_items) > cur_length: #make prediction\n",
        "            cur_length += 1\n",
        "            test_size += 1\n",
        "            # Predict the most similar items to items\n",
        "            predictions = model.predict_next(last_items, k = args.K)\n",
        "            # Evaluation\n",
        "            rank = 0\n",
        "            for predicted_item in predictions:\n",
        "                rank += 1\n",
        "                if predicted_item == item_id:\n",
        "                    hit += 1.0\n",
        "                    MRR += 1/rank\n",
        "                    break\n",
        "        \n",
        "        last_items.append(item_id)\n",
        "t2 = time.time()\n",
        "print('Recall: {}'.format(hit / test_size))\n",
        "print ('\\nMRR: {}'.format(MRR / test_size))\n",
        "print('End Model Predictions with total time =', t2 - t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxw9qqP1B3fO",
        "outputId": "4c6ce597-d74e-4e23-9a04-6e378c6af185"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished Reading Data \n",
            "Start Model Fitting...\n",
            "End Model Fitting with total time = 0.0548856258392334 \n",
            " Start Predictions...\n",
            "Recall: 0.2708333333333333\n",
            "\n",
            "MRR: 0.05646645021645023\n",
            "End Model Predictions with total time = 0.14295291900634766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HsgSkP0BJNmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mO6auo4VB3h5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "2-models_vsknn_recohut.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}