{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thesis-srgnn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOOlx6uB48HLvcvYOx6FYMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishanthjois/2021_DeepLearning/blob/main/thesis_srgnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HghcX5W6K0m5",
        "outputId": "62f9a9fb-5735-469a-92c8-1fc362dd03c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SR-GNN'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 50 (delta 1), reused 0 (delta 0), pack-reused 44\u001b[K\n",
            "Unpacking objects: 100% (50/50), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CRIPAC-DIG/SR-GNN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd SR-GNN; cd datasets; python preprocess.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTe60QOBLO-G",
        "outputId": "93ca1994-d22c-4abe-cec6-1b83ef2c495a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='sample')\n",
            "-- Starting @ 2022-01-29 09:34:44.724473s\n",
            "-- Reading data @ 2022-01-29 09:34:44.831342s\n",
            "Splitting date 1464134400.0\n",
            "469\n",
            "47\n",
            "[('2671', 1451952000.0), ('1211', 1452384000.0), ('3780', 1452384000.0)]\n",
            "[('1864', 1464220800.0), ('1867', 1464220800.0), ('1868', 1464220800.0)]\n",
            "-- Splitting train set and test set @ 2022-01-29 09:34:44.840492s\n",
            "310\n",
            "1205\n",
            "99\n",
            "[[1, 2], [1], [4]] [1451952000.0, 1451952000.0, 1452384000.0] [3, 2, 5]\n",
            "[[282], [281, 308], [281]] [1464220800.0, 1464220800.0, 1464220800.0] [282, 281, 308]\n",
            "avg length:  3.5669291338582676\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.13.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoJABEqoMTJr",
        "outputId": "8165358f-cae6-4e62-bd08-0bd8a47d1171"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "  Downloading tensorflow-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (92.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 92.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0\n",
            "  Downloading tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 61.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (1.43.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "  Downloading tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.1) (0.37.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.10.0.2)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.13.1) (1.5.2)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd SR-GNN; cd tensorflow_code; python main.py --dataset=sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Qjzzj-WMHid",
        "outputId": "a24ce149-136a-4933-c0cc-91c19fe38b3c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /content/SR-GNN/tensorflow_code/model.py:104: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/SR-GNN/tensorflow_code/model.py:116: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /content/SR-GNN/tensorflow_code/model.py:33: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2022-01-29 09:41:47.836215: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-01-29 09:41:47.839668: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2249995000 Hz\n",
            "2022-01-29 09:41:47.839879: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55d59e9df080 executing computations on platform Host. Devices:\n",
            "2022-01-29 09:41:47.839908: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "Namespace(batchSize=100, dataset='sample', epoch=30, hiddenSize=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=3, method='ggnn', nonhybrid=False, step=1, validation=False)\n",
            "epoch:  0 ===========================================\n",
            "start training:  2022-01-29 09:41:48.017518\n",
            "start predicting:  2022-01-29 09:41:50.166717\n",
            "train_loss:\t5.7242\ttest_loss:\t5.706389\tRecall@20:\t35.0000\tMMR@20:\t8.7340\tEpoch:\t0,\t0\n",
            "epoch:  1 ===========================================\n",
            "start training:  2022-01-29 09:41:50.507406\n",
            "start predicting:  2022-01-29 09:41:51.091087\n",
            "train_loss:\t5.5799\ttest_loss:\t5.671888\tRecall@20:\t35.0000\tMMR@20:\t10.6648\tEpoch:\t0,\t1\n",
            "epoch:  2 ===========================================\n",
            "start training:  2022-01-29 09:41:51.120659\n",
            "start predicting:  2022-01-29 09:41:51.711696\n",
            "train_loss:\t5.2189\ttest_loss:\t5.662973\tRecall@20:\t35.0000\tMMR@20:\t13.3185\tEpoch:\t0,\t2\n",
            "epoch:  3 ===========================================\n",
            "start training:  2022-01-29 09:41:51.738281\n",
            "start predicting:  2022-01-29 09:41:52.338824\n",
            "train_loss:\t4.9096\ttest_loss:\t5.624509\tRecall@20:\t35.0000\tMMR@20:\t14.0224\tEpoch:\t3,\t3\n",
            "epoch:  4 ===========================================\n",
            "start training:  2022-01-29 09:41:52.363882\n",
            "start predicting:  2022-01-29 09:41:52.931552\n",
            "train_loss:\t4.8501\ttest_loss:\t5.595503\tRecall@20:\t38.0000\tMMR@20:\t14.0224\tEpoch:\t4,\t3\n",
            "epoch:  5 ===========================================\n",
            "start training:  2022-01-29 09:41:52.958884\n",
            "start predicting:  2022-01-29 09:41:53.518369\n",
            "train_loss:\t4.7984\ttest_loss:\t5.576196\tRecall@20:\t40.0000\tMMR@20:\t14.7446\tEpoch:\t5,\t5\n",
            "epoch:  6 ===========================================\n",
            "start training:  2022-01-29 09:41:53.543639\n",
            "start predicting:  2022-01-29 09:41:54.137207\n",
            "train_loss:\t4.7629\ttest_loss:\t5.573672\tRecall@20:\t40.0000\tMMR@20:\t14.7447\tEpoch:\t6,\t6\n",
            "epoch:  7 ===========================================\n",
            "start training:  2022-01-29 09:41:54.162145\n",
            "start predicting:  2022-01-29 09:41:54.758369\n",
            "train_loss:\t4.7428\ttest_loss:\t5.571276\tRecall@20:\t40.0000\tMMR@20:\t14.7859\tEpoch:\t7,\t7\n",
            "epoch:  8 ===========================================\n",
            "start training:  2022-01-29 09:41:54.784030\n",
            "start predicting:  2022-01-29 09:41:55.376728\n",
            "train_loss:\t4.7531\ttest_loss:\t5.570251\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t8,\t8\n",
            "epoch:  9 ===========================================\n",
            "start training:  2022-01-29 09:41:55.406631\n",
            "start predicting:  2022-01-29 09:41:55.982838\n",
            "train_loss:\t4.7538\ttest_loss:\t5.570032\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t9,\t9\n",
            "epoch:  10 ===========================================\n",
            "start training:  2022-01-29 09:41:56.015419\n",
            "start predicting:  2022-01-29 09:41:56.594555\n",
            "train_loss:\t4.7562\ttest_loss:\t5.569835\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t10,\t10\n",
            "epoch:  11 ===========================================\n",
            "start training:  2022-01-29 09:41:56.620375\n",
            "start predicting:  2022-01-29 09:41:57.215605\n",
            "train_loss:\t4.7492\ttest_loss:\t5.569786\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t11,\t11\n",
            "epoch:  12 ===========================================\n",
            "start training:  2022-01-29 09:41:57.241068\n",
            "start predicting:  2022-01-29 09:41:57.829272\n",
            "train_loss:\t4.7475\ttest_loss:\t5.569766\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t12,\t12\n",
            "epoch:  13 ===========================================\n",
            "start training:  2022-01-29 09:41:57.854405\n",
            "start predicting:  2022-01-29 09:41:58.430110\n",
            "train_loss:\t4.7477\ttest_loss:\t5.569746\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t13,\t13\n",
            "epoch:  14 ===========================================\n",
            "start training:  2022-01-29 09:41:58.456191\n",
            "start predicting:  2022-01-29 09:41:59.028933\n",
            "train_loss:\t4.7362\ttest_loss:\t5.569744\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t14,\t14\n",
            "epoch:  15 ===========================================\n",
            "start training:  2022-01-29 09:41:59.053408\n",
            "start predicting:  2022-01-29 09:41:59.607059\n",
            "train_loss:\t4.7594\ttest_loss:\t5.569742\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t15,\t15\n",
            "epoch:  16 ===========================================\n",
            "start training:  2022-01-29 09:41:59.633036\n",
            "start predicting:  2022-01-29 09:42:00.197125\n",
            "train_loss:\t4.7491\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t16,\t16\n",
            "epoch:  17 ===========================================\n",
            "start training:  2022-01-29 09:42:00.222561\n",
            "start predicting:  2022-01-29 09:42:00.841698\n",
            "train_loss:\t4.7609\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t17,\t17\n",
            "epoch:  18 ===========================================\n",
            "start training:  2022-01-29 09:42:00.867680\n",
            "start predicting:  2022-01-29 09:42:01.448313\n",
            "train_loss:\t4.7688\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t18,\t18\n",
            "epoch:  19 ===========================================\n",
            "start training:  2022-01-29 09:42:01.475304\n",
            "start predicting:  2022-01-29 09:42:02.064568\n",
            "train_loss:\t4.7574\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t19,\t19\n",
            "epoch:  20 ===========================================\n",
            "start training:  2022-01-29 09:42:02.089191\n",
            "start predicting:  2022-01-29 09:42:02.659642\n",
            "train_loss:\t4.7507\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t20,\t20\n",
            "epoch:  21 ===========================================\n",
            "start training:  2022-01-29 09:42:02.684859\n",
            "start predicting:  2022-01-29 09:42:03.266513\n",
            "train_loss:\t4.7403\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t21,\t21\n",
            "epoch:  22 ===========================================\n",
            "start training:  2022-01-29 09:42:03.293282\n",
            "start predicting:  2022-01-29 09:42:03.872684\n",
            "train_loss:\t4.7297\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t22,\t22\n",
            "epoch:  23 ===========================================\n",
            "start training:  2022-01-29 09:42:03.897373\n",
            "start predicting:  2022-01-29 09:42:04.484415\n",
            "train_loss:\t4.7530\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t23,\t23\n",
            "epoch:  24 ===========================================\n",
            "start training:  2022-01-29 09:42:04.508531\n",
            "start predicting:  2022-01-29 09:42:05.064329\n",
            "train_loss:\t4.7457\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t24,\t24\n",
            "epoch:  25 ===========================================\n",
            "start training:  2022-01-29 09:42:05.088860\n",
            "start predicting:  2022-01-29 09:42:05.652950\n",
            "train_loss:\t4.7758\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t25,\t25\n",
            "epoch:  26 ===========================================\n",
            "start training:  2022-01-29 09:42:05.677901\n",
            "start predicting:  2022-01-29 09:42:06.258729\n",
            "train_loss:\t4.7564\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t26,\t26\n",
            "epoch:  27 ===========================================\n",
            "start training:  2022-01-29 09:42:06.286443\n",
            "start predicting:  2022-01-29 09:42:06.844743\n",
            "train_loss:\t4.7504\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t27,\t27\n",
            "epoch:  28 ===========================================\n",
            "start training:  2022-01-29 09:42:06.870523\n",
            "start predicting:  2022-01-29 09:42:07.444789\n",
            "train_loss:\t4.7623\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t28,\t28\n",
            "epoch:  29 ===========================================\n",
            "start training:  2022-01-29 09:42:07.470933\n",
            "start predicting:  2022-01-29 09:42:08.048511\n",
            "train_loss:\t4.7506\ttest_loss:\t5.569740\tRecall@20:\t40.0000\tMMR@20:\t14.7924\tEpoch:\t29,\t29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmP8qeysLfeI",
        "outputId": "5e358b4b-3e31-491f-d6fb-dda25ec9eea6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  SR-GNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_uIfoumULfhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IKhHaLVjLfjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vJLARTGYLPCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "9QsZ2vAlLQIr"
      }
    }
  ]
}